{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unityagents in ./venv/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.7/site-packages (from unityagents) (3.5.2)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.7/site-packages (from unityagents) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in ./venv/lib/python3.7/site-packages (from unityagents) (1.18.2)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in ./venv/lib/python3.7/site-packages (from unityagents) (7.1.1)\n",
      "Requirement already satisfied: pytest>=3.2.2 in ./venv/lib/python3.7/site-packages (from unityagents) (5.4.1)\n",
      "Requirement already satisfied: grpcio in ./venv/lib/python3.7/site-packages (from unityagents) (1.14.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.7/site-packages (from unityagents) (1.0.3)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.7/site-packages (from unityagents) (1.4.1)\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.7/site-packages (from unityagents) (5.2.1)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.7/site-packages (from unityagents) (3.2.1)\n",
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.7/site-packages (from unityagents) (2.0.1)\n",
      "Requirement already satisfied: docopt in ./venv/lib/python3.7/site-packages (from unityagents) (0.6.2)\n",
      "Requirement already satisfied: jupyter in ./venv/lib/python3.7/site-packages (from unityagents) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.7/site-packages (from unityagents) (5.3.1)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from protobuf->unityagents) (46.1.3)\n",
      "Requirement already satisfied: six>=1.9 in ./venv/lib/python3.7/site-packages (from protobuf->unityagents) (1.14.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (8.2.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (20.3)\n",
      "Requirement already satisfied: py>=1.5.0 in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (19.3.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (0.1.9)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (0.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in ./venv/lib/python3.7/site-packages (from pytest>=3.2.2->unityagents) (1.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./venv/lib/python3.7/site-packages (from pandas->unityagents) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./venv/lib/python3.7/site-packages (from pandas->unityagents) (2.8.1)\n",
      "Requirement already satisfied: jupyter-client in ./venv/lib/python3.7/site-packages (from ipykernel->unityagents) (6.1.3)\n",
      "Requirement already satisfied: ipython>=5.0.0 in ./venv/lib/python3.7/site-packages (from ipykernel->unityagents) (7.13.0)\n",
      "Requirement already satisfied: tornado>=4.2 in ./venv/lib/python3.7/site-packages (from ipykernel->unityagents) (6.0.4)\n",
      "Requirement already satisfied: appnope; platform_system == \"Darwin\" in ./venv/lib/python3.7/site-packages (from ipykernel->unityagents) (0.1.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in ./venv/lib/python3.7/site-packages (from ipykernel->unityagents) (4.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.7/site-packages (from matplotlib->unityagents) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./venv/lib/python3.7/site-packages (from matplotlib->unityagents) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.7/site-packages (from matplotlib->unityagents) (1.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (2.0.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (3.2.1)\n",
      "Requirement already satisfied: gast==0.2.2 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (1.12.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in ./venv/lib/python3.7/site-packages (from tensorflow->unityagents) (2.0.2)\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.7/site-packages (from jupyter->unityagents) (7.5.1)\n",
      "Requirement already satisfied: qtconsole in ./venv/lib/python3.7/site-packages (from jupyter->unityagents) (4.7.3)\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.7/site-packages (from jupyter->unityagents) (6.0.3)\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.7/site-packages (from jupyter->unityagents) (6.1.0)\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.7/site-packages (from jupyter->unityagents) (5.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=3.2.2->unityagents) (3.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in ./venv/lib/python3.7/site-packages (from jupyter-client->ipykernel->unityagents) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in ./venv/lib/python3.7/site-packages (from jupyter-client->ipykernel->unityagents) (19.0.0)\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (0.7.5)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (4.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (4.8.0)\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (0.17.0)\n",
      "Requirement already satisfied: pygments in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (2.6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./venv/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->unityagents) (3.0.5)\n",
      "Requirement already satisfied: ipython-genutils in ./venv/lib/python3.7/site-packages (from traitlets>=4.1.0->ipykernel->unityagents) (0.2.0)\n",
      "Requirement already satisfied: h5py in ./venv/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow->unityagents) (2.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./venv/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (1.14.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (1.0.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./venv/lib/python3.7/site-packages (from ipywidgets->jupyter->unityagents) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./venv/lib/python3.7/site-packages (from ipywidgets->jupyter->unityagents) (5.0.5)\n",
      "Requirement already satisfied: qtpy in ./venv/lib/python3.7/site-packages (from qtconsole->jupyter->unityagents) (1.9.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in ./venv/lib/python3.7/site-packages (from notebook->jupyter->unityagents) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.7/site-packages (from notebook->jupyter->unityagents) (2.11.2)\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.7/site-packages (from notebook->jupyter->unityagents) (0.7.1)\n",
      "Requirement already satisfied: Send2Trash in ./venv/lib/python3.7/site-packages (from notebook->jupyter->unityagents) (1.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (0.8.4)\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (3.1.4)\n",
      "Requirement already satisfied: testpath in ./venv/lib/python3.7/site-packages (from nbconvert->jupyter->unityagents) (0.4.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->unityagents) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.7.0 in ./venv/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->unityagents) (0.7.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in ./venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (4.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./venv/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->unityagents) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./venv/lib/python3.7/site-packages (from jinja2->notebook->jupyter->unityagents) (1.1.1)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.7/site-packages (from bleach->nbconvert->jupyter->unityagents) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow->unityagents) (0.4.8)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in ./venv/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->unityagents) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unityagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "#env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")\n",
    "env = UnityEnvironment(file_name=\"Banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Add-on : Set plotting options\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(precision=3, linewidth=120)\n",
    "# Add-on : Hide Matplotlib deprecate warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# High resolution plot outputs for retina display\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.    0.    0.    0.    0.844 0.    0.    1.    0.    0.075 0.    1.    0.    0.    0.258 1.    0.    0.    0.\n",
      " 0.742 0.    1.    0.    0.    0.259 0.    0.    1.    0.    0.094 0.    1.    0.    0.    0.32  0.    0.   ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Agent with DQN\n",
    "\n",
    "A reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana.  Thus, the goal of your agent is to collect as many yellow bananas as possible while avoiding blue bananas.  \n",
    "\n",
    "The state space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  Given this information, the agent has to learn how to best select actions.  Four discrete actions are available, corresponding to:\n",
    "- **`0`** - move forward.\n",
    "- **`1`** - move backward.\n",
    "- **`2`** - turn left.\n",
    "- **`3`** - turn right.\n",
    "\n",
    "The task is episodic, and in order to solve the environment, your agent must get an average score of +13 over 100 consecutive episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.09\n",
      "Episode 200\tAverage Score: 5.41\n",
      "Episode 300\tAverage Score: 8.96\n",
      "Episode 319\tAverage Score: 8.65"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4962b088bf3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4962b088bf3d>\u001b[0m in \u001b[0;36mdqn\u001b[0;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# send the action to the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# get the next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;31m# get the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/udacity/banana/venv/lib/python3.7/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/udacity/banana/venv/lib/python3.7/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dqn_agent import Agent\n",
    "SEED = 42\n",
    "state_size = 37\n",
    "action_size = 4\n",
    "def dqn(n_episodes=2000,\n",
    "        max_t=1000, \n",
    "        eps_start=1.0, \n",
    "        eps_end=0.1, \n",
    "        eps_decay=0.99):\n",
    "    \"\"\"Deep Q-Network learning\n",
    "    \"\"\"\n",
    "    agent = Agent(state_size, action_size, SEED)\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]   \n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            \n",
    "            action = agent.act(state, epsilon)\n",
    "            \n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # get the done status\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        scores_window.append(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "        epsilon = max(eps_end, epsilon*eps_decay)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
